# # pip install pyyaml
# Random Forest:
#   n_estimators: 100
#   max_depth: 10
#   random_state: 42

# Decision Tree:
#   max_depth: 5
#   random_state: 42

# XGBRegressor:
#   learning_rate: 0.1
#   n_estimators: 100
#   max_depth: 3

# CatBoosting Regressor:
#   iterations: 100
#   learning_rate: 0.1
#   depth: 6

# AdaBoost Regressor:
#   n_estimators: 100
#   learning_rate: 0.1

# KNeighbors Regressor:
#   n_neighbors: 5

# SVC:
#   C: 1.0
#   kernel: 'rbf'
#   degree: 3
#   gamma: 'scale'
#   probability: True

# # and with the ff code as model trainer
# import os
# import sys
# import yaml
# from dataclasses import dataclass

# from catboost import CatBoostRegressor
# from sklearn.ensemble import (
#     AdaBoostRegressor,
#     RandomForestRegressor,
# )
# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import r2_score
# from sklearn.neighbors import KNeighborsRegressor
# from sklearn.svm import SVC
# from sklearn.tree import DecisionTreeRegressor
# from xgboost import XGBRegressor

# from src.exception import CustomException
# from src.logger import logging
# from src.utils import save_object, evaluate_models

# @dataclass
# class ModelTrainerConfig:
#     trained_model_file_path = os.path.join("artifacts", "model.pkl")
#     config_file_path = os.path.join("config", "config.yaml")  # Configuration file for model parameters

# class ModelTrainer:
#     def __init__(self):
#         self.model_trainer_config = ModelTrainerConfig()

#     def load_params_from_yaml(self):
#         with open(self.model_trainer_config.config_file_path, "r") as yaml_file:
#             params = yaml.safe_load(yaml_file)
#         return params

#     def initiate_model_trainer(self, train_array, test_array):
#         try:
#             logging.info("Split training and test input data")
#             X_train, y_train, X_test, y_test = (
#                 train_array[:, :-1],
#                 train_array[:, -1],
#                 test_array[:, :-1],
#                 test_array[:, -1]
#             )

#             # Load model parameters from config.yaml
#             params = self.load_params_from_yaml()

#             models = {
#                 "Random Forest": RandomForestRegressor(**params.get("Random Forest", {})),
#                 "Decision Tree": DecisionTreeRegressor(**params.get("Decision Tree", {})),
#                 "Linear Regression": LinearRegression(),
#                 "XGBRegressor": XGBRegressor(**params.get("XGBRegressor", {})),
#                 "CatBoosting Regressor": CatBoostRegressor(verbose=False, **params.get("CatBoosting Regressor", {})),
#                 "AdaBoost Regressor": AdaBoostRegressor(**params.get("AdaBoost Regressor", {})),
#                 "SVC": SVC(probability=True, **params.get("SVC", {})),
#                 "KNeighbors": KNeighborsRegressor(**params.get("KNeighbors", {}))
#             }

#             model_report = evaluate_models(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,
#                                            models=models, param=params)

#             best_model_score = max(sorted(model_report.values()))
#             best_model_name = list(model_report.keys())[
#                 list(model_report.values()).index(best_model_score)
#             ]
#             best_model = models[best_model_name]

#             if best_model_score < 0.6:
#                 raise CustomException("No best model found")
#             logging.info(f"Best found model on both training and testing dataset")

#             save_object(
#                 file_path=self.model_trainer_config.trained_model_file_path,
#                 obj=best_model
#             )

#             predicted = best_model.predict(X_test)

#             r2_square = r2_score(y_test, predicted)
#             return r2_square

#         except Exception as e:
#             raise CustomException(e, sys)
